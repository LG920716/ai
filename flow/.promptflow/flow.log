2024-05-15 11:06:15 +0800   40761 execution.flow     INFO     Start executing nodes in thread pool mode.
2024-05-15 11:06:15 +0800   40761 execution.flow     INFO     Start to run 5 nodes with concurrency level 16.
2024-05-15 11:06:15 +0800   40761 execution.flow     INFO     Executing node Summary. node run id: 904bcc8f-aba0-48a9-ad5d-b8f7ec744107_Summary_0
2024-05-15 11:06:15 +0800   40761 execution.flow     INFO     Executing node prepare_examples. node run id: 904bcc8f-aba0-48a9-ad5d-b8f7ec744107_prepare_examples_0
2024-05-15 11:06:15 +0800   40761 execution.flow     INFO     Node prepare_examples completes.
2024-05-15 11:06:15 +0800   40761 execution.flow     INFO     Node Summary completes.
2024-05-15 11:06:15 +0800   40761 execution.flow     INFO     Executing node Embedding_inputs. node run id: 904bcc8f-aba0-48a9-ad5d-b8f7ec744107_Embedding_inputs_0
2024-05-15 11:06:16 +0800   40761 execution.flow     INFO     Node Embedding_inputs completes.
2024-05-15 11:06:16 +0800   40761 execution.flow     INFO     Executing node seach_from_ai_search. node run id: 904bcc8f-aba0-48a9-ad5d-b8f7ec744107_seach_from_ai_search_0
2024-05-15 11:06:17 +0800   40761 execution.flow     INFO     Node seach_from_ai_search completes.
2024-05-15 11:06:17 +0800   40761 execution.flow     INFO     Executing node chat. node run id: 904bcc8f-aba0-48a9-ad5d-b8f7ec744107_chat_0
2024-05-15 11:06:18 +0800   40761 execution.flow     WARNING  Failed to calculate metrics due to exception: Calculating metrics for model chat16k is not supported..
2024-05-15 11:06:18 +0800   40761 execution.flow     WARNING  Output of chat is not json serializable, use str to store it.
2024-05-15 11:06:18 +0800   40761 execution.flow     INFO     Node chat completes.
2024-05-15 11:06:18 +0800   40761 execution.flow     WARNING  Failed to serialize inputs or output for flow run because of cannot pickle 'generator' object.The inputs and output field in api_calls will be None.
2024-05-15 11:07:05 +0800   40761 execution.flow     INFO     Start executing nodes in thread pool mode.
2024-05-15 11:07:05 +0800   40761 execution.flow     INFO     Start to run 5 nodes with concurrency level 16.
2024-05-15 11:07:05 +0800   40761 execution.flow     INFO     Executing node Summary. node run id: 066e23ff-036e-4db5-9a11-544d99fc88d7_Summary_0
2024-05-15 11:07:05 +0800   40761 execution.flow     INFO     Executing node prepare_examples. node run id: 066e23ff-036e-4db5-9a11-544d99fc88d7_prepare_examples_0
2024-05-15 11:07:05 +0800   40761 execution.flow     INFO     Node prepare_examples completes.
2024-05-15 11:07:06 +0800   40761 execution.flow     INFO     Node Summary completes.
2024-05-15 11:07:06 +0800   40761 execution.flow     INFO     Executing node Embedding_inputs. node run id: 066e23ff-036e-4db5-9a11-544d99fc88d7_Embedding_inputs_0
2024-05-15 11:07:06 +0800   40761 execution.flow     INFO     Node Embedding_inputs completes.
2024-05-15 11:07:06 +0800   40761 execution.flow     INFO     Executing node seach_from_ai_search. node run id: 066e23ff-036e-4db5-9a11-544d99fc88d7_seach_from_ai_search_0
2024-05-15 11:07:07 +0800   40761 execution.flow     INFO     Node seach_from_ai_search completes.
2024-05-15 11:07:07 +0800   40761 execution.flow     INFO     Executing node chat. node run id: 066e23ff-036e-4db5-9a11-544d99fc88d7_chat_0
2024-05-15 11:07:07 +0800   40761 execution.flow     WARNING  Failed to calculate metrics due to exception: Calculating metrics for model chat16k is not supported..
2024-05-15 11:07:07 +0800   40761 execution.flow     WARNING  Output of chat is not json serializable, use str to store it.
2024-05-15 11:07:07 +0800   40761 execution.flow     INFO     Node chat completes.
2024-05-15 11:07:07 +0800   40761 execution.flow     WARNING  Failed to serialize inputs or output for flow run because of cannot pickle 'generator' object.The inputs and output field in api_calls will be None.
2024-05-15 11:07:17 +0800   40761 execution.flow     INFO     Start executing nodes in thread pool mode.
2024-05-15 11:07:17 +0800   40761 execution.flow     INFO     Start to run 5 nodes with concurrency level 16.
2024-05-15 11:07:17 +0800   40761 execution.flow     INFO     Executing node Summary. node run id: 78df7e26-de03-469e-b4e6-b06b84958232_Summary_0
2024-05-15 11:07:17 +0800   40761 execution.flow     INFO     Executing node prepare_examples. node run id: 78df7e26-de03-469e-b4e6-b06b84958232_prepare_examples_0
2024-05-15 11:07:17 +0800   40761 execution.flow     INFO     Node prepare_examples completes.
2024-05-15 11:07:20 +0800   40761 execution.flow     INFO     Node Summary completes.
2024-05-15 11:07:20 +0800   40761 execution.flow     INFO     Executing node Embedding_inputs. node run id: 78df7e26-de03-469e-b4e6-b06b84958232_Embedding_inputs_0
2024-05-15 11:07:20 +0800   40761 execution.flow     INFO     Node Embedding_inputs completes.
2024-05-15 11:07:20 +0800   40761 execution.flow     INFO     Executing node seach_from_ai_search. node run id: 78df7e26-de03-469e-b4e6-b06b84958232_seach_from_ai_search_0
2024-05-15 11:07:21 +0800   40761 execution.flow     INFO     Node seach_from_ai_search completes.
2024-05-15 11:07:21 +0800   40761 execution.flow     INFO     Executing node chat. node run id: 78df7e26-de03-469e-b4e6-b06b84958232_chat_0
2024-05-15 11:07:21 +0800   40761 execution.flow     WARNING  Failed to calculate metrics due to exception: Calculating metrics for model chat16k is not supported..
2024-05-15 11:07:21 +0800   40761 execution.flow     WARNING  Output of chat is not json serializable, use str to store it.
2024-05-15 11:07:21 +0800   40761 execution.flow     INFO     Node chat completes.
2024-05-15 11:07:21 +0800   40761 execution.flow     WARNING  Failed to serialize inputs or output for flow run because of cannot pickle 'generator' object.The inputs and output field in api_calls will be None.
2024-05-15 11:07:46 +0800   40761 execution.flow     INFO     Start executing nodes in thread pool mode.
2024-05-15 11:07:46 +0800   40761 execution.flow     INFO     Start to run 5 nodes with concurrency level 16.
2024-05-15 11:07:46 +0800   40761 execution.flow     INFO     Executing node Summary. node run id: 65a7e16b-cd9c-441a-acf9-97d94a0d27f6_Summary_0
2024-05-15 11:07:46 +0800   40761 execution.flow     INFO     Executing node prepare_examples. node run id: 65a7e16b-cd9c-441a-acf9-97d94a0d27f6_prepare_examples_0
2024-05-15 11:07:46 +0800   40761 execution.flow     INFO     Node prepare_examples completes.
2024-05-15 11:07:47 +0800   40761 execution.flow     INFO     Node Summary completes.
2024-05-15 11:07:47 +0800   40761 execution.flow     INFO     Executing node Embedding_inputs. node run id: 65a7e16b-cd9c-441a-acf9-97d94a0d27f6_Embedding_inputs_0
2024-05-15 11:07:48 +0800   40761 execution.flow     INFO     Node Embedding_inputs completes.
2024-05-15 11:07:48 +0800   40761 execution.flow     INFO     Executing node seach_from_ai_search. node run id: 65a7e16b-cd9c-441a-acf9-97d94a0d27f6_seach_from_ai_search_0
2024-05-15 11:07:48 +0800   40761 execution.flow     INFO     Node seach_from_ai_search completes.
2024-05-15 11:07:48 +0800   40761 execution.flow     INFO     Executing node chat. node run id: 65a7e16b-cd9c-441a-acf9-97d94a0d27f6_chat_0
2024-05-15 11:07:49 +0800   40761 execution          WARNING  [chat in line 0 (index starts from 0)] stderr> Exception occurs: BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 16384 tokens. However, you requested 18080 tokens (13984 in the messages, 4096 in the completion). Please reduce the length of the messages or completion.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}
2024-05-15 11:07:49 +0800   40761 execution          ERROR    Node chat in line 0 failed. Exception: OpenAI API hits BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 16384 tokens. However, you requested 18080 tokens (13984 in the messages, 4096 in the completion). Please reduce the length of the messages or completion.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}} [Error reference: https://platform.openai.com/docs/guides/error-codes/api-errors].
Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/promptflow/tools/common.py", line 353, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/promptflow/tools/aoai.py", line 154, in chat
    completion = self._client.chat.completions.create(**params)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ray.huang/Desktop/promptflow/src/promptflow-tracing/promptflow/tracing/_integrations/_openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/ray.huang/Desktop/promptflow/src/promptflow-tracing/promptflow/tracing/_trace.py", line 470, in wrapped
    output = func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openai/_utils/_utils.py", line 277, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openai/resources/chat/completions.py", line 579, in create
    return self._post(
           ^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openai/_base_client.py", line 1240, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openai/_base_client.py", line 921, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openai/_base_client.py", line 1020, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 16384 tokens. However, you requested 18080 tokens (13984 in the messages, 4096 in the completion). Please reduce the length of the messages or completion.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/promptflow/_core/flow_execution_context.py", line 90, in invoke_tool
    result = self._invoke_tool_inner(node, f, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/promptflow/_core/flow_execution_context.py", line 201, in _invoke_tool_inner
    raise e
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/promptflow/_core/flow_execution_context.py", line 182, in _invoke_tool_inner
    return f(**kwargs)
           ^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/promptflow/executor/flow_executor.py", line 1267, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/ray.huang/Desktop/promptflow/src/promptflow-tracing/promptflow/tracing/_trace.py", line 470, in wrapped
    output = func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/promptflow/tools/common.py", line 381, in wrapper
    raise WrappedOpenAIError(e)
promptflow.tools.exception.WrappedOpenAIError: OpenAI API hits BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 16384 tokens. However, you requested 18080 tokens (13984 in the messages, 4096 in the completion). Please reduce the length of the messages or completion.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}} [Error reference: https://platform.openai.com/docs/guides/error-codes/api-errors]
2024-05-15 11:07:49 +0800   40761 execution.flow     ERROR    Flow execution has failed. Cancelling all running nodes: chat.
