2024-05-16 15:18:54 +0800   65276 execution.flow     INFO     Start executing nodes in thread pool mode.
2024-05-16 15:18:54 +0800   65276 execution.flow     INFO     Start to run 5 nodes with concurrency level 16.
2024-05-16 15:18:54 +0800   65276 execution.flow     INFO     Executing node Summary. node run id: 01ad361f-5350-4ada-8d35-c679657365fb_Summary_0
2024-05-16 15:18:54 +0800   65276 execution.flow     INFO     Executing node prepare_examples. node run id: 01ad361f-5350-4ada-8d35-c679657365fb_prepare_examples_0
2024-05-16 15:18:54 +0800   65276 execution.flow     INFO     Node prepare_examples completes.
2024-05-16 15:18:54 +0800   65276 execution.flow     INFO     Node Summary completes.
2024-05-16 15:18:54 +0800   65276 execution.flow     INFO     Executing node Embedding_inputs. node run id: 01ad361f-5350-4ada-8d35-c679657365fb_Embedding_inputs_0
2024-05-16 15:18:55 +0800   65276 execution.flow     INFO     Node Embedding_inputs completes.
2024-05-16 15:18:55 +0800   65276 execution.flow     INFO     Executing node seach_from_ai_search. node run id: 01ad361f-5350-4ada-8d35-c679657365fb_seach_from_ai_search_0
2024-05-16 15:18:56 +0800   65276 execution.flow     INFO     Node seach_from_ai_search completes.
2024-05-16 15:18:56 +0800   65276 execution.flow     INFO     Executing node chat. node run id: 01ad361f-5350-4ada-8d35-c679657365fb_chat_0
2024-05-16 15:18:56 +0800   65276 execution.flow     WARNING  Failed to calculate metrics due to exception: Calculating metrics for model chat16k is not supported..
2024-05-16 15:18:56 +0800   65276 execution.flow     WARNING  Output of chat is not json serializable, use str to store it.
2024-05-16 15:18:56 +0800   65276 execution.flow     INFO     Node chat completes.
2024-05-16 15:18:56 +0800   65276 execution.flow     WARNING  Failed to serialize inputs or output for flow run because of cannot pickle 'generator' object.The inputs and output field in api_calls will be None.
2024-05-16 15:19:11 +0800   65276 execution.flow     INFO     Start executing nodes in thread pool mode.
2024-05-16 15:19:11 +0800   65276 execution.flow     INFO     Start to run 5 nodes with concurrency level 16.
2024-05-16 15:19:11 +0800   65276 execution.flow     INFO     Executing node Summary. node run id: 16102b0a-18d6-48fa-9ca1-84d1b6fbd590_Summary_0
2024-05-16 15:19:11 +0800   65276 execution.flow     INFO     Executing node prepare_examples. node run id: 16102b0a-18d6-48fa-9ca1-84d1b6fbd590_prepare_examples_0
2024-05-16 15:19:11 +0800   65276 execution.flow     INFO     Node prepare_examples completes.
2024-05-16 15:19:18 +0800   65276 execution.flow     INFO     Node Summary completes.
2024-05-16 15:19:18 +0800   65276 execution.flow     INFO     Executing node Embedding_inputs. node run id: 16102b0a-18d6-48fa-9ca1-84d1b6fbd590_Embedding_inputs_0
2024-05-16 15:19:19 +0800   65276 execution.flow     INFO     Node Embedding_inputs completes.
2024-05-16 15:19:19 +0800   65276 execution.flow     INFO     Executing node seach_from_ai_search. node run id: 16102b0a-18d6-48fa-9ca1-84d1b6fbd590_seach_from_ai_search_0
2024-05-16 15:19:19 +0800   65276 execution.flow     INFO     Node seach_from_ai_search completes.
2024-05-16 15:19:19 +0800   65276 execution.flow     INFO     Executing node chat. node run id: 16102b0a-18d6-48fa-9ca1-84d1b6fbd590_chat_0
2024-05-16 15:19:20 +0800   65276 execution.flow     WARNING  Failed to calculate metrics due to exception: Calculating metrics for model chat16k is not supported..
2024-05-16 15:19:20 +0800   65276 execution.flow     WARNING  Output of chat is not json serializable, use str to store it.
2024-05-16 15:19:20 +0800   65276 execution.flow     INFO     Node chat completes.
2024-05-16 15:19:20 +0800   65276 execution.flow     WARNING  Failed to serialize inputs or output for flow run because of cannot pickle 'generator' object.The inputs and output field in api_calls will be None.
2024-05-16 15:21:48 +0800   65276 execution.flow     INFO     Start executing nodes in thread pool mode.
2024-05-16 15:21:48 +0800   65276 execution.flow     INFO     Start to run 5 nodes with concurrency level 16.
2024-05-16 15:21:48 +0800   65276 execution.flow     INFO     Executing node Summary. node run id: ca40dafd-d188-4153-8ed8-e981bc2a8795_Summary_0
2024-05-16 15:21:48 +0800   65276 execution.flow     INFO     Executing node prepare_examples. node run id: ca40dafd-d188-4153-8ed8-e981bc2a8795_prepare_examples_0
2024-05-16 15:21:48 +0800   65276 execution.flow     INFO     Node prepare_examples completes.
2024-05-16 15:21:49 +0800   65276 execution.flow     INFO     Node Summary completes.
2024-05-16 15:21:49 +0800   65276 execution.flow     INFO     Executing node Embedding_inputs. node run id: ca40dafd-d188-4153-8ed8-e981bc2a8795_Embedding_inputs_0
2024-05-16 15:21:49 +0800   65276 execution.flow     INFO     Node Embedding_inputs completes.
2024-05-16 15:21:49 +0800   65276 execution.flow     INFO     Executing node seach_from_ai_search. node run id: ca40dafd-d188-4153-8ed8-e981bc2a8795_seach_from_ai_search_0
2024-05-16 15:21:50 +0800   65276 execution.flow     INFO     Node seach_from_ai_search completes.
2024-05-16 15:21:50 +0800   65276 execution.flow     INFO     Executing node chat. node run id: ca40dafd-d188-4153-8ed8-e981bc2a8795_chat_0
2024-05-16 15:21:50 +0800   65276 execution.flow     WARNING  Failed to calculate metrics due to exception: Calculating metrics for model chat16k is not supported..
2024-05-16 15:21:50 +0800   65276 execution.flow     WARNING  Output of chat is not json serializable, use str to store it.
2024-05-16 15:21:50 +0800   65276 execution.flow     INFO     Node chat completes.
2024-05-16 15:21:50 +0800   65276 execution.flow     WARNING  Failed to serialize inputs or output for flow run because of cannot pickle 'generator' object.The inputs and output field in api_calls will be None.
2024-05-16 15:22:10 +0800   65276 execution.flow     INFO     Start executing nodes in thread pool mode.
2024-05-16 15:22:10 +0800   65276 execution.flow     INFO     Start to run 5 nodes with concurrency level 16.
2024-05-16 15:22:10 +0800   65276 execution.flow     INFO     Executing node Summary. node run id: 99c2b392-6a98-40ff-95e0-8be00c3f0397_Summary_0
2024-05-16 15:22:10 +0800   65276 execution.flow     INFO     Executing node prepare_examples. node run id: 99c2b392-6a98-40ff-95e0-8be00c3f0397_prepare_examples_0
2024-05-16 15:22:10 +0800   65276 execution.flow     INFO     Node prepare_examples completes.
2024-05-16 15:22:13 +0800   65276 execution.flow     INFO     Node Summary completes.
2024-05-16 15:22:13 +0800   65276 execution.flow     INFO     Executing node Embedding_inputs. node run id: 99c2b392-6a98-40ff-95e0-8be00c3f0397_Embedding_inputs_0
2024-05-16 15:22:14 +0800   65276 execution.flow     INFO     Node Embedding_inputs completes.
2024-05-16 15:22:14 +0800   65276 execution.flow     INFO     Executing node seach_from_ai_search. node run id: 99c2b392-6a98-40ff-95e0-8be00c3f0397_seach_from_ai_search_0
2024-05-16 15:22:14 +0800   65276 execution.flow     INFO     Node seach_from_ai_search completes.
2024-05-16 15:22:14 +0800   65276 execution.flow     INFO     Executing node chat. node run id: 99c2b392-6a98-40ff-95e0-8be00c3f0397_chat_0
2024-05-16 15:22:15 +0800   65276 execution          WARNING  [chat in line 0 (index starts from 0)] stderr> Exception occurs: BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 16384 tokens. However, you requested 18750 tokens (14654 in the messages, 4096 in the completion). Please reduce the length of the messages or completion.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}
2024-05-16 15:22:15 +0800   65276 execution          ERROR    Node chat in line 0 failed. Exception: OpenAI API hits BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 16384 tokens. However, you requested 18750 tokens (14654 in the messages, 4096 in the completion). Please reduce the length of the messages or completion.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}} [Error reference: https://platform.openai.com/docs/guides/error-codes/api-errors].
Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/promptflow/tools/common.py", line 353, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/promptflow/tools/aoai.py", line 154, in chat
    completion = self._client.chat.completions.create(**params)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/ray.huang/Desktop/promptflow/src/promptflow-tracing/promptflow/tracing/_integrations/_openai_injector.py", line 88, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/ray.huang/Desktop/promptflow/src/promptflow-tracing/promptflow/tracing/_trace.py", line 470, in wrapped
    output = func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openai/_utils/_utils.py", line 277, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openai/resources/chat/completions.py", line 579, in create
    return self._post(
           ^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openai/_base_client.py", line 1240, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openai/_base_client.py", line 921, in request
    return self._request(
           ^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/openai/_base_client.py", line 1020, in _request
    raise self._make_status_error_from_response(err.response) from None
openai.BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 16384 tokens. However, you requested 18750 tokens (14654 in the messages, 4096 in the completion). Please reduce the length of the messages or completion.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/promptflow/_core/flow_execution_context.py", line 90, in invoke_tool
    result = self._invoke_tool_inner(node, f, kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/promptflow/_core/flow_execution_context.py", line 201, in _invoke_tool_inner
    raise e
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/promptflow/_core/flow_execution_context.py", line 182, in _invoke_tool_inner
    return f(**kwargs)
           ^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/promptflow/executor/flow_executor.py", line 1267, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/Users/ray.huang/Desktop/promptflow/src/promptflow-tracing/promptflow/tracing/_trace.py", line 470, in wrapped
    output = func(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^^^
  File "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/promptflow/tools/common.py", line 381, in wrapper
    raise WrappedOpenAIError(e)
promptflow.tools.exception.WrappedOpenAIError: OpenAI API hits BadRequestError: Error code: 400 - {'error': {'message': "This model's maximum context length is 16384 tokens. However, you requested 18750 tokens (14654 in the messages, 4096 in the completion). Please reduce the length of the messages or completion.", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}} [Error reference: https://platform.openai.com/docs/guides/error-codes/api-errors]
2024-05-16 15:22:15 +0800   65276 execution.flow     ERROR    Flow execution has failed. Cancelling all running nodes: chat.
